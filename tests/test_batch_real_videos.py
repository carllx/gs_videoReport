#!/usr/bin/env python3
"""
æ‰¹é‡å¤„ç†åŠŸèƒ½ - åŸºäºçœŸå®Figmaæ•™ç¨‹è§†é¢‘çš„QAæµ‹è¯•
ä½¿ç”¨test_videosç›®å½•ä¸­çš„çœŸå®è§†é¢‘æ–‡ä»¶è¿›è¡Œæµ‹è¯•
"""

import json
import pytest
import tempfile
import shutil
from pathlib import Path
from unittest.mock import Mock, patch
from datetime import datetime
import time

import sys
sys.path.append(str(Path(__file__).parent.parent / "src"))

from gs_video_report.batch.simple_processor import SimpleBatchProcessor
from gs_video_report.config import Config


class TestBatchProcessingWithRealVideos:
    """åŸºäºçœŸå®è§†é¢‘æ–‡ä»¶çš„æ‰¹é‡å¤„ç†æµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•ç¯å¢ƒè®¾ç½® - ä½¿ç”¨çœŸå®çš„test_videosç›®å½•"""
        self.project_root = Path(__file__).parent.parent
        self.test_videos_dir = self.project_root / "test_videos"
        
        # éªŒè¯çœŸå®è§†é¢‘æ–‡ä»¶å­˜åœ¨
        if not self.test_videos_dir.exists():
            pytest.skip("çœŸå®è§†é¢‘ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
        
        # è·å–æ‰€æœ‰çœŸå®è§†é¢‘æ–‡ä»¶
        self.video_files = list(self.test_videos_dir.glob("*.mp4"))
        if len(self.video_files) == 0:
            pytest.skip("æ²¡æœ‰æ‰¾åˆ°çœŸå®è§†é¢‘æ–‡ä»¶ï¼Œè·³è¿‡æµ‹è¯•")
        
        print(f"ğŸ“ å‘ç° {len(self.video_files)} ä¸ªçœŸå®Figmaæ•™ç¨‹è§†é¢‘")
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
        self.temp_output_dir = Path(tempfile.mkdtemp())
        
        # åˆ›å»ºçœŸå®é…ç½®
        config_data = {
            'google_api': {
                'api_key': 'test_api_key_for_qa',  # å°†è¢«mock
                'model': 'gemini-2.5-flash',
                'temperature': 0.7,
                'max_tokens': 8192
            },
            'templates': {
                'default_template': 'chinese_transcript',
                'template_path': 'src/gs_video_report/templates/prompts'
            },
            'output': {
                'default_path': str(self.temp_output_dir),
                'file_naming': '{video_title}_{timestamp}',
                'include_metadata': True
            }
        }
        self.config = Config(config_data)
        
        # æ¸…ç†ä¹‹å‰çš„çŠ¶æ€æ–‡ä»¶
        self._cleanup_state_files()
        
    def teardown_method(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        if self.temp_output_dir.exists():
            shutil.rmtree(self.temp_output_dir)
        self._cleanup_state_files()
    
    def _cleanup_state_files(self):
        """æ¸…ç†çŠ¶æ€æ–‡ä»¶"""
        state_files = list(self.project_root.glob("batch_*_state.json"))
        for state_file in state_files:
            try:
                state_file.unlink()
            except FileNotFoundError:
                pass
    
    @patch('gs_video_report.batch.simple_processor.GeminiService')
    @patch('gs_video_report.batch.simple_processor.TemplateManager')
    def test_real_video_error_isolation(self, mock_template_manager, mock_gemini_service):
        """
        æµ‹è¯•1: çœŸå®è§†é¢‘é”™è¯¯éš”ç¦»æœºåˆ¶
        ç›®æ ‡ï¼šä½¿ç”¨çœŸå®è§†é¢‘éªŒè¯é”™è¯¯éš”ç¦»åŠŸèƒ½
        """
        mock_service_instance = Mock()
        mock_gemini_service.return_value = mock_service_instance
        
        # æ¨¡æ‹Ÿéƒ¨åˆ†æˆåŠŸã€éƒ¨åˆ†å¤±è´¥çš„åœºæ™¯
        call_count = 0
        def realistic_side_effect(*args, **kwargs):
            nonlocal call_count
            call_count += 1
            video_path = args[0] if args else kwargs.get('video_path', '')
            
            # æ¨¡æ‹Ÿï¼šå‰å‡ ä¸ªæˆåŠŸï¼Œä¸­é—´å‡ ä¸ªå¤±è´¥ï¼Œåé¢å‡ ä¸ªæˆåŠŸ
            if call_count % 4 == 0:  # æ¯4ä¸ªä¸­æœ‰1ä¸ªå¤±è´¥
                raise Exception(f"æ¨¡æ‹Ÿå¤„ç†å¤±è´¥: {Path(video_path).name}")
            else:
                return Mock(output_path=video_path.replace('.mp4', '_lesson.md'))
        
        mock_service_instance.process_video_end_to_end.side_effect = realistic_side_effect
        
        # æ‰§è¡Œæ‰¹é‡å¤„ç†
        processor = SimpleBatchProcessor(self.config)
        result = processor.process_directory(str(self.test_videos_dir), output_dir=str(self.temp_output_dir))
        
        # éªŒè¯ç»“æœ
        expected_total = len(self.video_files)  # åº”è¯¥æ˜¯20ä¸ªè§†é¢‘æ–‡ä»¶
        
        assert result["total"] == expected_total, f"å¤„ç†è§†é¢‘æ•°é‡ä¸ç¬¦: {result['total']} != {expected_total}"
        assert result["success"] >= int(expected_total * 0.7), f"æˆåŠŸç‡è¿‡ä½: {result['success']}/{expected_total}"
        assert result["failed"] <= int(expected_total * 0.3), f"å¤±è´¥ç‡è¿‡é«˜: {result['failed']}/{expected_total}"
        
        # éªŒè¯é”™è¯¯éš”ç¦»ï¼šæˆåŠŸçš„è§†é¢‘ä¸å—å¤±è´¥è§†é¢‘å½±å“
        assert result["success"] + result["failed"] + result["skipped"] == result["total"]
        
        # éªŒè¯çŠ¶æ€æ–‡ä»¶
        state_files = list(self.project_root.glob("batch_*_state.json"))
        assert len(state_files) >= 1
        
        with open(state_files[0], 'r', encoding='utf-8') as f:
            state_data = json.load(f)
        
        assert state_data["total"] == expected_total
        assert len(state_data["results"]) == expected_total
        
        print(f"âœ… é”™è¯¯éš”ç¦»æµ‹è¯•é€šè¿‡ - æˆåŠŸ: {result['success']}, å¤±è´¥: {result['failed']}")
        
        self._cleanup_state_files()
    
    @patch('gs_video_report.batch.simple_processor.GeminiService')
    @patch('gs_video_report.batch.simple_processor.TemplateManager')
    def test_real_video_retry_mechanism(self, mock_template_manager, mock_gemini_service):
        """
        æµ‹è¯•2: çœŸå®è§†é¢‘é‡è¯•æœºåˆ¶éªŒè¯
        ç›®æ ‡ï¼šéªŒè¯ç½‘ç»œé”™è¯¯æ—¶çš„é‡è¯•åŠŸèƒ½
        """
        mock_service_instance = Mock()
        mock_gemini_service.return_value = mock_service_instance
        
        # æµ‹è¯•å‰3ä¸ªè§†é¢‘çš„é‡è¯•æœºåˆ¶
        test_videos = self.video_files[:3]
        test_videos_dir = self.temp_output_dir / "test_subset"
        test_videos_dir.mkdir()
        
        # å¤åˆ¶å‰3ä¸ªè§†é¢‘åˆ°æµ‹è¯•ç›®å½•ï¼ˆå»ºç«‹è½¯é“¾æ¥é¿å…å¤åˆ¶å¤§æ–‡ä»¶ï¼‰
        for video in test_videos:
            link_path = test_videos_dir / video.name
            link_path.symlink_to(video)
        
        # æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯é‡è¯•
        retry_counts = {}
        def retry_side_effect(*args, **kwargs):
            video_path = args[0] if args else kwargs.get('video_path', '')
            video_name = Path(video_path).name
            
            if video_name not in retry_counts:
                retry_counts[video_name] = 0
            retry_counts[video_name] += 1
            
            # å‰2æ¬¡å¤±è´¥ï¼ˆç½‘ç»œé”™è¯¯ï¼‰ï¼Œç¬¬3æ¬¡æˆåŠŸ
            if retry_counts[video_name] <= 2:
                raise Exception("Network timeout - connection failed")
            else:
                return Mock(output_path=video_path.replace('.mp4', '_lesson.md'))
        
        mock_service_instance.process_video_end_to_end.side_effect = retry_side_effect
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        processor = SimpleBatchProcessor(self.config)
        result = processor.process_directory(str(test_videos_dir), max_retries=3)
        
        end_time = time.time()
        
        # éªŒè¯é‡è¯•æœºåˆ¶
        assert result["total"] == 3
        assert result["success"] == 3  # æœ€ç»ˆéƒ½åº”è¯¥æˆåŠŸ
        
        # éªŒè¯æ¯ä¸ªè§†é¢‘éƒ½é‡è¯•äº†3æ¬¡
        for video_name, count in retry_counts.items():
            assert count == 3, f"{video_name} é‡è¯•æ¬¡æ•°ä¸æ­£ç¡®: {count} != 3"
        
        # éªŒè¯æŒ‡æ•°é€€é¿å»¶è¿Ÿï¼ˆåº”è¯¥æœ‰è¶³å¤Ÿçš„å»¶è¿Ÿæ—¶é—´ï¼‰
        expected_min_delay = 3 * (1 + 2 + 4)  # 3ä¸ªè§†é¢‘ * (1+2+4ç§’é€€é¿)
        actual_duration = end_time - start_time
        assert actual_duration >= expected_min_delay * 0.8, f"é‡è¯•å»¶è¿Ÿæ—¶é—´ä¸è¶³: {actual_duration:.2f}s < {expected_min_delay}s"
        
        print(f"âœ… é‡è¯•æœºåˆ¶æµ‹è¯•é€šè¿‡ - å¤„ç†æ—¶é—´: {actual_duration:.2f}s, é‡è¯•ç»Ÿè®¡: {retry_counts}")
        
        self._cleanup_state_files()
    
    @patch('gs_video_report.batch.simple_processor.GeminiService')
    @patch('gs_video_report.batch.simple_processor.TemplateManager')
    def test_real_video_skip_existing(self, mock_template_manager, mock_gemini_service):
        """
        æµ‹è¯•3: çœŸå®è§†é¢‘è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶åŠŸèƒ½
        ç›®æ ‡ï¼šéªŒè¯--skip-existingå‚æ•°çš„æ–­ç‚¹ç»­ä¼ æ•ˆæœ
        """
        mock_service_instance = Mock()
        mock_gemini_service.return_value = mock_service_instance
        mock_service_instance.process_video_end_to_end.return_value = Mock(
            output_path="new_output.md"
        )
        
        # ä½¿ç”¨å‰5ä¸ªè§†é¢‘è¿›è¡Œæµ‹è¯•
        test_videos = self.video_files[:5]
        test_videos_dir = self.temp_output_dir / "skip_test"
        test_videos_dir.mkdir()
        
        # åˆ›å»ºè½¯é“¾æ¥
        for video in test_videos:
            link_path = test_videos_dir / video.name
            link_path.symlink_to(video)
        
        # é¢„å…ˆåˆ›å»ºä¸€äº›"å·²å¤„ç†"çš„è¾“å‡ºæ–‡ä»¶
        pre_existing_files = [
            test_videos[0].stem + "_lesson.md",  # ç¬¬1ä¸ªè§†é¢‘çš„è¾“å‡º
            test_videos[2].stem + "_lesson.md",  # ç¬¬3ä¸ªè§†é¢‘çš„è¾“å‡º
        ]
        
        for filename in pre_existing_files:
            output_file = self.temp_output_dir / filename
            output_file.write_text("å·²å­˜åœ¨çš„è¾“å‡ºå†…å®¹")
        
        # æ‰§è¡Œæ‰¹é‡å¤„ç†ï¼ˆå¯ç”¨è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶ï¼‰
        processor = SimpleBatchProcessor(self.config)
        result = processor.process_directory(
            str(test_videos_dir), 
            output_dir=str(self.temp_output_dir),
            skip_existing=True
        )
        
        # éªŒè¯è·³è¿‡åŠŸèƒ½
        assert result["total"] == 5
        assert result["skipped"] == 2  # åº”è¯¥è·³è¿‡2ä¸ªå·²å­˜åœ¨çš„æ–‡ä»¶
        assert result["success"] == 3   # å¤„ç†3ä¸ªæ–°æ–‡ä»¶
        assert result["failed"] == 0
        
        # éªŒè¯çŠ¶æ€æ–‡ä»¶è®°å½•æ­£ç¡®
        state_files = list(self.project_root.glob("batch_*_state.json"))
        with open(state_files[0], 'r', encoding='utf-8') as f:
            state_data = json.load(f)
        
        skipped_results = [r for r in state_data["results"] if r["status"] == "skipped"]
        success_results = [r for r in state_data["results"] if r["status"] == "success"]
        
        assert len(skipped_results) == 2
        assert len(success_results) == 3
        
        print(f"âœ… è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶æµ‹è¯•é€šè¿‡ - è·³è¿‡: {result['skipped']}, æ–°å¤„ç†: {result['success']}")
        
        self._cleanup_state_files()
    
    @patch('gs_video_report.batch.simple_processor.GeminiService')
    @patch('gs_video_report.batch.simple_processor.TemplateManager')
    def test_real_video_performance_benchmark(self, mock_template_manager, mock_gemini_service):
        """
        æµ‹è¯•4: çœŸå®è§†é¢‘æ€§èƒ½åŸºå‡†æµ‹è¯•
        ç›®æ ‡ï¼šå»ºç«‹åŸºäºçœŸå®20ä¸ªFigmaè§†é¢‘çš„æ€§èƒ½åŸºå‡†
        """
        mock_service_instance = Mock()
        mock_gemini_service.return_value = mock_service_instance
        
        # æ¨¡æ‹ŸçœŸå®çš„å¤„ç†å»¶è¿Ÿ
        def realistic_processing_simulation(*args, **kwargs):
            video_path = args[0] if args else kwargs.get('video_path', '')
            video_file = Path(video_path)
            
            # åŸºäºæ–‡ä»¶åæ¨¡æ‹Ÿä¸åŒçš„å¤„ç†æ—¶é—´
            base_delay = 0.5  # åŸºç¡€å»¶è¿Ÿ
            
            # æ ¹æ®æ–‡ä»¶åé•¿åº¦å’Œå†…å®¹æ¨¡æ‹Ÿå¤„ç†å¤æ‚åº¦
            complexity_factor = len(video_file.name) / 100.0
            processing_delay = base_delay + complexity_factor
            
            time.sleep(processing_delay)
            return Mock(output_path=video_path.replace('.mp4', '_lesson.md'))
        
        mock_service_instance.process_video_end_to_end.side_effect = realistic_processing_simulation
        
        # æ‰§è¡Œæ€§èƒ½æµ‹è¯•
        start_time = time.time()
        processor = SimpleBatchProcessor(self.config)
        result = processor.process_directory(str(self.test_videos_dir), output_dir=str(self.temp_output_dir))
        end_time = time.time()
        
        total_duration = end_time - start_time
        
        # æ€§èƒ½åŸºå‡†éªŒè¯
        expected_video_count = 20
        assert result["total"] == expected_video_count
        assert result["success"] == expected_video_count  # åº”è¯¥å…¨éƒ¨æˆåŠŸ
        
        # ååé‡è®¡ç®—
        throughput = result["total"] / total_duration * 60  # files/minute
        avg_per_video = total_duration / result["total"]    # seconds/video
        
        # æ€§èƒ½åŸºå‡†æ–­è¨€
        assert total_duration < 1800, f"æ€»å¤„ç†æ—¶é—´è¶…æ ‡: {total_duration:.2f}s > 30åˆ†é’Ÿ"
        assert throughput >= 0.8, f"ååé‡è¿‡ä½: {throughput:.2f} files/min < 0.8"
        assert avg_per_video < 60, f"å¹³å‡æ¯è§†é¢‘å¤„ç†æ—¶é—´è¿‡é•¿: {avg_per_video:.2f}s > 60s"
        
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        performance_report = {
            'test_name': 'real_figma_videos_performance_benchmark',
            'video_count': expected_video_count,
            'total_duration_seconds': total_duration,
            'throughput_files_per_minute': throughput,
            'avg_seconds_per_video': avg_per_video,
            'success_rate': result["success"] / result["total"],
            'test_timestamp': datetime.now().isoformat(),
            'video_files': [f.name for f in self.video_files],
            'benchmark_criteria': {
                'max_total_duration_seconds': 1800,
                'min_throughput_files_per_minute': 0.8,
                'max_avg_seconds_per_video': 60,
                'min_success_rate': 0.95
            },
            'result': 'PASS'
        }
        
        # ä¿å­˜æ€§èƒ½åŸºå‡†æŠ¥å‘Š
        benchmark_file = self.project_root / "tests" / "real_video_performance_benchmark.json"
        with open(benchmark_file, 'w', encoding='utf-8') as f:
            json.dump(performance_report, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… çœŸå®è§†é¢‘æ€§èƒ½åŸºå‡†æµ‹è¯•é€šè¿‡:")
        print(f"   ğŸ“Š è§†é¢‘æ•°é‡: {expected_video_count}")
        print(f"   â±ï¸  æ€»å¤„ç†æ—¶é—´: {total_duration:.1f}ç§’")
        print(f"   ğŸš€ ååé‡: {throughput:.2f} files/min")
        print(f"   ğŸ“ˆ å¹³å‡æ¯è§†é¢‘: {avg_per_video:.2f}ç§’")
        print(f"   ğŸ“„ åŸºå‡†æŠ¥å‘Š: {benchmark_file}")
        
        self._cleanup_state_files()
    
    def test_real_video_files_validation(self):
        """
        æµ‹è¯•5: çœŸå®è§†é¢‘æ–‡ä»¶éªŒè¯
        ç›®æ ‡ï¼šéªŒè¯test_videosç›®å½•ä¸­çš„æ–‡ä»¶ç¡®å®æ˜¯æœ‰æ•ˆè§†é¢‘
        """
        expected_videos = [
            "001 - introduction-to-figma-essentials-training-course.mp4.mp4",
            "002 - getting-started-with-figma-training.mp4.mp4", 
            "003 - what-is-figma-for-does-it-do-the-coding.mp4.mp4",
            "004 - whats-the-difference-between-ui-and-ux-in-figma.mp4.mp4",
            "005 - what-we-are-making-in-this-figma-course.mp4.mp4",
            "006 - class-project-001-create-your-own-brief.mp4.mp4",
            "007 - what-is-lo-fi-wireframe-vs-high-fidelity-in-figma.mp4.mp4",
            "008 - creating-our-design-file-introducing-frames-in-figma.mp4.mp4",
            "009 - the-basics-of-type-fonts-in-figma.mp4_2.mp4",
            "010 - rectangles-circles-buttons-rounded-corners-in-figma.mp4.mp4",
            "011 - how-to-use-color-in-figma.mp4.mp4",
            "012 - strokes-plus-updating-color-defaults-in-figma.mp4.mp4",
            "013 - object-editing-and-how-to-escape-in-figma.mp4.mp4",
            "014 - scale-vs-selection-tool-in-figma.mp4.mp4",
            "015 - frames-vs-groups-in-figma.mp4.mp4",
            "016 - class-project-002-wireframe.mp4.mp4",
            "017 - where-to-get-free-icons-for-figma.mp4.mp4",
            "018 - matching-the-stroke-of-our-icons.mp4.mp4",
            "019 - how-to-use-plugins-in-figma-for-icons.mp4.mp4",
            "020 - class-project-003-icons.mp4.mp4"
        ]
        
        # éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§å’Œæ•°é‡
        actual_videos = [f.name for f in self.video_files]
        assert len(actual_videos) == 20, f"è§†é¢‘æ–‡ä»¶æ•°é‡ä¸å¯¹: {len(actual_videos)} != 20"
        
        # éªŒè¯é¢„æœŸçš„è§†é¢‘æ–‡ä»¶éƒ½å­˜åœ¨
        for expected_video in expected_videos:
            assert expected_video in actual_videos, f"ç¼ºå°‘é¢„æœŸè§†é¢‘: {expected_video}"
        
        # éªŒè¯æ–‡ä»¶å¤§å°ï¼ˆçœŸå®è§†é¢‘æ–‡ä»¶åº”è¯¥æœ‰åˆç†çš„å¤§å°ï¼‰
        total_size_mb = sum(f.stat().st_size for f in self.video_files) / 1024 / 1024
        avg_size_mb = total_size_mb / len(self.video_files)
        
        assert total_size_mb > 100, f"æ€»æ–‡ä»¶å¤§å°è¿‡å°ï¼Œå¯èƒ½ä¸æ˜¯çœŸå®è§†é¢‘: {total_size_mb:.1f}MB"
        assert avg_size_mb > 1, f"å¹³å‡æ–‡ä»¶å¤§å°è¿‡å°: {avg_size_mb:.1f}MB"
        
        print(f"âœ… çœŸå®è§†é¢‘æ–‡ä»¶éªŒè¯é€šè¿‡:")
        print(f"   ğŸ“ æ–‡ä»¶æ•°é‡: {len(actual_videos)}")
        print(f"   ğŸ“Š æ€»å¤§å°: {total_size_mb:.1f}MB")
        print(f"   ğŸ“ˆ å¹³å‡å¤§å°: {avg_size_mb:.1f}MB/æ–‡ä»¶")


if __name__ == "__main__":
    # è¿è¡ŒçœŸå®è§†é¢‘æµ‹è¯•
    print("ğŸ¬ å¼€å§‹æ‰§è¡ŒåŸºäºçœŸå®Figmaæ•™ç¨‹è§†é¢‘çš„QAæµ‹è¯•...")
    
    import subprocess
    
    # æ‰§è¡Œå…³é”®æµ‹è¯•
    critical_tests = [
        "TestBatchProcessingWithRealVideos::test_real_video_files_validation",
        "TestBatchProcessingWithRealVideos::test_real_video_error_isolation", 
        "TestBatchProcessingWithRealVideos::test_real_video_performance_benchmark"
    ]
    
    for test_case in critical_tests:
        print(f"\nğŸ§ª æ‰§è¡Œ: {test_case}")
        result = subprocess.run([
            sys.executable, "-m", "pytest",
            f"{__file__}::{test_case}",
            "-v", "--tb=short"
        ], cwd=Path(__file__).parent.parent)
        
        if result.returncode == 0:
            print(f"âœ… {test_case} æµ‹è¯•é€šè¿‡")
        else:
            print(f"âŒ {test_case} æµ‹è¯•å¤±è´¥")
