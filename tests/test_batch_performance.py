#!/usr/bin/env python3
"""
æ‰¹é‡å¤„ç†åŠŸèƒ½ - æ€§èƒ½åŸºå‡†æµ‹è¯•
é‡ç‚¹ï¼šéªŒè¯æ‰¹é‡å¤„ç†çš„ååé‡ã€å†…å­˜ä½¿ç”¨å’Œç¨³å®šæ€§
"""

import json
import pytest  
import tempfile
import shutil
import psutil
import time
from pathlib import Path
from unittest.mock import Mock, patch
from datetime import datetime
import threading
import statistics
from typing import List, Dict, Any

import sys
sys.path.append(str(Path(__file__).parent.parent / "src"))

from gs_video_report.batch.simple_processor import SimpleBatchProcessor
from gs_video_report.config import Config


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å·¥å…·ç±»"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.start_time = None
        self.memory_samples = []
        self.cpu_samples = []
        self.monitoring = False
        self.monitor_thread = None
    
    def start_monitoring(self):
        """å¼€å§‹æ€§èƒ½ç›‘æ§"""
        self.start_time = time.time()
        self.monitoring = True
        self.memory_samples = []
        self.cpu_samples = []
        
        def monitor_loop():
            while self.monitoring:
                try:
                    memory_info = self.process.memory_info()
                    cpu_percent = self.process.cpu_percent()
                    
                    self.memory_samples.append({
                        'timestamp': time.time(),
                        'rss': memory_info.rss / 1024 / 1024,  # MB
                        'vms': memory_info.vms / 1024 / 1024,  # MB
                    })
                    self.cpu_samples.append(cpu_percent)
                    
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    break
                    
                time.sleep(0.5)  # æ¯0.5ç§’é‡‡æ ·ä¸€æ¬¡
        
        self.monitor_thread = threading.Thread(target=monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
    
    def stop_monitoring(self) -> Dict[str, Any]:
        """åœæ­¢ç›‘æ§å¹¶è¿”å›ç»Ÿè®¡æ•°æ®"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=2.0)
        
        end_time = time.time()
        duration = end_time - self.start_time if self.start_time else 0
        
        if not self.memory_samples:
            return {'duration': duration, 'error': 'No samples collected'}
        
        rss_values = [sample['rss'] for sample in self.memory_samples]
        vms_values = [sample['vms'] for sample in self.memory_samples]
        
        return {
            'duration': duration,
            'memory': {
                'peak_rss_mb': max(rss_values),
                'avg_rss_mb': statistics.mean(rss_values),
                'peak_vms_mb': max(vms_values),
                'avg_vms_mb': statistics.mean(vms_values),
            },
            'cpu': {
                'avg_cpu_percent': statistics.mean(self.cpu_samples) if self.cpu_samples else 0,
                'max_cpu_percent': max(self.cpu_samples) if self.cpu_samples else 0,
            },
            'samples_count': len(self.memory_samples)
        }


class TestBatchPerformanceBenchmark:
    """æ‰¹é‡å¤„ç†æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•ç¯å¢ƒè®¾ç½®"""
        self.temp_dir = Path(tempfile.mkdtemp())
        self.test_videos_dir = self.temp_dir / "videos"
        self.test_videos_dir.mkdir()
        
        # åˆ›å»ºæ€§èƒ½æµ‹è¯•é…ç½®
        config_data = {
            'google_api': {
                'api_key': 'test_api_key',
                'model': 'gemini-2.5-flash',
                'temperature': 0.7,
                'max_tokens': 8192
            },
            'templates': {
                'default_template': 'chinese_transcript',
                'template_path': 'src/gs_video_report/templates/prompts'
            },
            'output': {
                'default_path': str(self.temp_dir / "output"),
                'file_naming': '{video_title}_{timestamp}',
                'include_metadata': True
            }
        }
        self.config = Config(config_data)
        self.monitor = PerformanceMonitor()
        
    def teardown_method(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        if self.temp_dir.exists():
            shutil.rmtree(self.temp_dir)
    
    def create_test_video_files(self, count: int, size_kb: int = 1024):
        """åˆ›å»ºæŒ‡å®šæ•°é‡å’Œå¤§å°çš„æµ‹è¯•è§†é¢‘æ–‡ä»¶"""
        content = "fake video content " * (size_kb // 20)  # å¤§è‡´æ¨¡æ‹ŸæŒ‡å®šå¤§å°
        
        for i in range(count):
            video_file = self.test_videos_dir / f"test_video_{i:03d}.mp4"
            video_file.write_text(content)
    
    def simulate_processing_delay(self, min_delay: float = 0.1, max_delay: float = 0.5):
        """æ¨¡æ‹Ÿè§†é¢‘å¤„ç†å»¶è¿Ÿï¼ˆç”¨äºæ€§èƒ½æµ‹è¯•ï¼‰"""
        import random
        delay = random.uniform(min_delay, max_delay)
        time.sleep(delay)
        return Mock(output_path=f"output_{random.randint(1000,9999)}.md")
    
    @patch('gs_video_report.batch.simple_processor.GeminiService')
    @patch('gs_video_report.batch.simple_processor.TemplateManager')
    def test_c1_small_batch_performance_baseline(self, mock_template_manager, mock_gemini_service):
        """
        æµ‹è¯•C1: å°æ‰¹é‡æ€§èƒ½åŸºçº¿æµ‹è¯• (5-10ä¸ªæ–‡ä»¶)
        ç›®æ ‡ï¼šå»ºç«‹å°æ‰¹é‡å¤„ç†çš„æ€§èƒ½åŸºå‡†
        """
        # åˆ›å»º10ä¸ªæµ‹è¯•è§†é¢‘æ–‡ä»¶
        self.create_test_video_files(count=10, size_kb=2048)  # 2MB each
        
        # è®¾ç½®æ¨¡æ‹ŸæœåŠ¡ - æ¨¡æ‹ŸçœŸå®çš„å¤„ç†å»¶è¿Ÿ
        mock_service_instance = Mock()
        mock_gemini_service.return_value = mock_service_instance
        mock_service_instance.process_video_end_to_end.side_effect = lambda *args, **kwargs: self.simulate_processing_delay(0.2, 1.0)
        
        # å¼€å§‹æ€§èƒ½ç›‘æ§
        self.monitor.start_monitoring()
        
        # æ‰§è¡Œæ‰¹é‡å¤„ç†
        processor = SimpleBatchProcessor(self.config)
        start_time = time.time()
        result = processor.process_directory(str(self.test_videos_dir))
        end_time = time.time()
        
        # åœæ­¢ç›‘æ§å¹¶è·å–æ€§èƒ½æ•°æ®
        perf_data = self.monitor.stop_monitoring()
        
        # æ€§èƒ½åŸºçº¿éªŒè¯
        processing_time = end_time - start_time
        assert processing_time < 300, f"å°æ‰¹é‡å¤„ç†æ—¶é—´è¶…æ ‡: {processing_time:.2f}ç§’ > 300ç§’"
        assert result["success"] == 10, f"æˆåŠŸç‡æœªè¾¾æ ‡: {result['success']}/10"
        assert perf_data['memory']['peak_rss_mb'] < 1024, f"å†…å­˜ä½¿ç”¨è¶…æ ‡: {perf_data['memory']['peak_rss_mb']:.2f}MB > 1024MB"
        
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        performance_report = {
            'test_name': 'C1_small_batch_baseline',
            'file_count': 10,
            'file_size_kb': 2048,
            'processing_time_seconds': processing_time,
            'throughput_files_per_minute': (result["total"] / processing_time) * 60,
            'success_rate': result["success"] / result["total"],
            'performance_metrics': perf_data,
            'pass_criteria': {
                'time_limit_seconds': 300,
                'memory_limit_mb': 1024,
                'success_rate_min': 0.9
            },
            'result': 'PASS'
        }
        
        # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
        report_file = self.temp_dir / "c1_performance_report.json"
        with open(report_file, 'w') as f:
            json.dump(performance_report, f, indent=2)
        
        print(f"âœ… C1æµ‹è¯•é€šè¿‡ - å¤„ç†æ—¶é—´: {processing_time:.2f}s, å†…å­˜å³°å€¼: {perf_data['memory']['peak_rss_mb']:.2f}MB")
        
        # æ¸…ç†çŠ¶æ€æ–‡ä»¶
        self._cleanup_state_files()
    
    @patch('gs_video_report.batch.simple_processor.GeminiService')
    @patch('gs_video_report.batch.simple_processor.TemplateManager')
    def test_c2_medium_batch_performance(self, mock_template_manager, mock_gemini_service):
        """
        æµ‹è¯•C2: ä¸­ç­‰æ‰¹é‡æ€§èƒ½æµ‹è¯• (20ä¸ªæ–‡ä»¶)
        ç›®æ ‡ï¼šéªŒè¯ç±»ä¼¼test_videosç›®å½•è§„æ¨¡çš„å¤„ç†æ€§èƒ½
        """
        # åˆ›å»º20ä¸ªæµ‹è¯•è§†é¢‘æ–‡ä»¶ï¼Œæ¨¡æ‹ŸçœŸå®çš„Figmaæ•™ç¨‹æ–‡ä»¶
        self.create_test_video_files(count=20, size_kb=5120)  # 5MB each, ç±»ä¼¼çœŸå®è§†é¢‘å¤§å°
        
        mock_service_instance = Mock()
        mock_gemini_service.return_value = mock_service_instance
        mock_service_instance.process_video_end_to_end.side_effect = lambda *args, **kwargs: self.simulate_processing_delay(0.5, 2.0)
        
        # å¼€å§‹ç›‘æ§
        self.monitor.start_monitoring()
        
        # æ‰§è¡Œå¤„ç†
        processor = SimpleBatchProcessor(self.config)
        start_time = time.time()
        result = processor.process_directory(str(self.test_videos_dir))
        end_time = time.time()
        
        perf_data = self.monitor.stop_monitoring()
        
        # ä¸­ç­‰æ‰¹é‡æ€§èƒ½éªŒè¯
        processing_time = end_time - start_time
        assert processing_time < 1800, f"ä¸­ç­‰æ‰¹é‡å¤„ç†æ—¶é—´è¶…æ ‡: {processing_time:.2f}ç§’ > 1800ç§’"  # 30åˆ†é’Ÿé™åˆ¶
        assert result["success"] >= 18, f"æˆåŠŸç‡è¿‡ä½: {result['success']}/20 < 18/20"
        assert perf_data['memory']['peak_rss_mb'] < 1024, f"å†…å­˜ä½¿ç”¨è¿‡é«˜: {perf_data['memory']['peak_rss_mb']:.2f}MB"
        
        # ååé‡éªŒè¯
        throughput = (result["total"] / processing_time) * 60  # files per minute
        assert throughput >= 0.8, f"ååé‡è¿‡ä½: {throughput:.2f} files/min < 0.8"
        
        # æ€§èƒ½æŠ¥å‘Š
        performance_report = {
            'test_name': 'C2_medium_batch_performance',
            'file_count': 20,
            'file_size_kb': 5120,
            'processing_time_seconds': processing_time,
            'throughput_files_per_minute': throughput,
            'success_rate': result["success"] / result["total"],
            'performance_metrics': perf_data,
            'pass_criteria': {
                'time_limit_seconds': 1800,
                'memory_limit_mb': 1024,
                'throughput_min_files_per_min': 0.8,
                'success_rate_min': 0.9
            },
            'result': 'PASS'
        }
        
        report_file = self.temp_dir / "c2_performance_report.json"
        with open(report_file, 'w') as f:
            json.dump(performance_report, f, indent=2)
        
        print(f"âœ… C2æµ‹è¯•é€šè¿‡ - å¤„ç†æ—¶é—´: {processing_time:.2f}s, ååé‡: {throughput:.2f} files/min")
        
        self._cleanup_state_files()
    
    @patch('gs_video_report.batch.simple_processor.GeminiService')
    @patch('gs_video_report.batch.simple_processor.TemplateManager')
    def test_c3_large_batch_stress_test(self, mock_template_manager, mock_gemini_service):
        """
        æµ‹è¯•C3: å¤§æ‰¹é‡å‹åŠ›æµ‹è¯• (50ä¸ªæ–‡ä»¶)
        ç›®æ ‡ï¼šéªŒè¯å¤§æ‰¹é‡å¤„ç†çš„ç¨³å®šæ€§å’Œå†…å­˜ç®¡ç†
        """
        # åˆ›å»º50ä¸ªæµ‹è¯•æ–‡ä»¶ï¼Œæ¨¡æ‹Ÿå‹åŠ›æµ‹è¯•åœºæ™¯
        self.create_test_video_files(count=50, size_kb=3072)  # 3MB each
        
        mock_service_instance = Mock()
        mock_gemini_service.return_value = mock_service_instance
        mock_service_instance.process_video_end_to_end.side_effect = lambda *args, **kwargs: self.simulate_processing_delay(0.3, 1.5)
        
        # å¼€å§‹ç›‘æ§
        self.monitor.start_monitoring()
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        # æ‰§è¡Œå¤§æ‰¹é‡å¤„ç†
        processor = SimpleBatchProcessor(self.config)
        start_time = time.time()
        result = processor.process_directory(str(self.test_videos_dir))
        end_time = time.time()
        
        perf_data = self.monitor.stop_monitoring()
        final_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        # å‹åŠ›æµ‹è¯•éªŒè¯
        processing_time = end_time - start_time
        memory_growth = final_memory - initial_memory
        
        # ç¨³å®šæ€§æ£€æŸ¥
        assert result["success"] >= 45, f"å¤§æ‰¹é‡æˆåŠŸç‡è¿‡ä½: {result['success']}/50 < 45/50"
        assert memory_growth < 500, f"å†…å­˜å¢é•¿è¿‡å¤§: {memory_growth:.2f}MB (å¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼)"
        assert perf_data['memory']['peak_rss_mb'] < 1536, f"å†…å­˜å³°å€¼è¿‡é«˜: {perf_data['memory']['peak_rss_mb']:.2f}MB"
        
        # æ€§èƒ½ç¨³å®šæ€§æ£€æŸ¥
        memory_samples = [sample['rss'] for sample in perf_data.get('memory_samples', [])]
        if len(memory_samples) > 10:
            # æ£€æŸ¥å†…å­˜ä½¿ç”¨æ˜¯å¦ç¨³å®šï¼ˆååŠç¨‹ç›¸å¯¹å‰åŠç¨‹å¢é•¿ä¸è¶…è¿‡50%ï¼‰
            mid_point = len(memory_samples) // 2
            first_half_avg = statistics.mean(memory_samples[:mid_point])
            second_half_avg = statistics.mean(memory_samples[mid_point:])
            growth_rate = (second_half_avg - first_half_avg) / first_half_avg
            
            assert growth_rate < 0.5, f"å†…å­˜ä½¿ç”¨å¢é•¿ç‡è¿‡é«˜: {growth_rate:.2%} > 50% (ç–‘ä¼¼å†…å­˜æ³„æ¼)"
        
        # å‹åŠ›æµ‹è¯•æŠ¥å‘Š
        performance_report = {
            'test_name': 'C3_large_batch_stress_test',
            'file_count': 50,
            'file_size_kb': 3072,
            'processing_time_seconds': processing_time,
            'throughput_files_per_minute': (result["total"] / processing_time) * 60,
            'success_rate': result["success"] / result["total"],
            'memory_analysis': {
                'initial_mb': initial_memory,
                'final_mb': final_memory,
                'growth_mb': memory_growth,
                'peak_mb': perf_data['memory']['peak_rss_mb']
            },
            'performance_metrics': perf_data,
            'stability_checks': {
                'memory_growth_limit_mb': 500,
                'peak_memory_limit_mb': 1536,
                'success_rate_min': 0.9
            },
            'result': 'PASS'
        }
        
        report_file = self.temp_dir / "c3_stress_test_report.json"
        with open(report_file, 'w') as f:
            json.dump(performance_report, f, indent=2)
        
        print(f"âœ… C3å‹åŠ›æµ‹è¯•é€šè¿‡ - å¤„ç†æ—¶é—´: {processing_time:.2f}s, å†…å­˜å¢é•¿: {memory_growth:.2f}MB")
        
        self._cleanup_state_files()
    
    @patch('gs_video_report.batch.simple_processor.GeminiService')
    @patch('gs_video_report.batch.simple_processor.TemplateManager')
    def test_state_file_performance_impact(self, mock_template_manager, mock_gemini_service):
        """
        æµ‹è¯•D1: çŠ¶æ€æ–‡ä»¶å†™å…¥æ€§èƒ½å½±å“
        ç›®æ ‡ï¼šéªŒè¯çŠ¶æ€æŒä¹…åŒ–ä¸ä¼šæ˜¾è‘—å½±å“å¤„ç†æ€§èƒ½
        """
        self.create_test_video_files(count=20)
        
        mock_service_instance = Mock()
        mock_gemini_service.return_value = mock_service_instance
        mock_service_instance.process_video_end_to_end.side_effect = lambda *args, **kwargs: self.simulate_processing_delay(0.1, 0.3)
        
        processor = SimpleBatchProcessor(self.config)
        
        # æµ‹è¯•1: æ­£å¸¸çŠ¶æ€ä¿å­˜
        start_time = time.time()
        result = processor.process_directory(str(self.test_videos_dir))
        normal_time = time.time() - start_time
        
        self._cleanup_state_files()
        
        # æµ‹è¯•2: æ¨¡æ‹ŸçŠ¶æ€æ–‡ä»¶å†™å…¥å¤±è´¥çš„æƒ…å†µï¼ˆé€šè¿‡Mockï¼‰
        original_save_state = processor._save_state
        def mock_failing_save_state(*args, **kwargs):
            time.sleep(0.01)  # æ¨¡æ‹Ÿå†™å…¥å»¶è¿Ÿä½†å¤±è´¥
            pass  # ä¸å®é™…ä¿å­˜
        
        processor._save_state = mock_failing_save_state
        
        start_time = time.time()
        result_no_save = processor.process_directory(str(self.test_videos_dir))
        no_save_time = time.time() - start_time
        
        # æ€§èƒ½å½±å“åˆ†æ
        performance_overhead = (normal_time - no_save_time) / no_save_time if no_save_time > 0 else 0
        
        # éªŒè¯çŠ¶æ€ä¿å­˜çš„æ€§èƒ½å¼€é”€åœ¨å¯æ¥å—èŒƒå›´å†…
        assert performance_overhead < 0.1, f"çŠ¶æ€ä¿å­˜æ€§èƒ½å¼€é”€è¿‡å¤§: {performance_overhead:.2%} > 10%"
        assert result["success"] == result_no_save["success"], "çŠ¶æ€ä¿å­˜å½±å“äº†å¤„ç†æˆåŠŸç‡"
        
        print(f"âœ… çŠ¶æ€æ–‡ä»¶æ€§èƒ½å½±å“æµ‹è¯•é€šè¿‡ - å¼€é”€: {performance_overhead:.2%}")
    
    def _cleanup_state_files(self):
        """æ¸…ç†ç”Ÿæˆçš„çŠ¶æ€æ–‡ä»¶"""
        state_files = list(Path().glob("batch_*_state.json"))
        for state_file in state_files:
            try:
                state_file.unlink()
            except FileNotFoundError:
                pass


class TestRealWorldPerformance:
    """ä½¿ç”¨çœŸå®test_videosæ•°æ®çš„æ€§èƒ½æµ‹è¯•"""
    
    def setup_method(self):
        """ä½¿ç”¨é¡¹ç›®ä¸­çš„çœŸå®æµ‹è¯•æ•°æ®"""
        self.project_root = Path(__file__).parent.parent
        self.test_videos_dir = self.project_root / "test_videos"
        
        # æ£€æŸ¥çœŸå®æµ‹è¯•æ•°æ®æ˜¯å¦å­˜åœ¨
        if not self.test_videos_dir.exists():
            pytest.skip("çœŸå®æµ‹è¯•æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡çœŸå®æ€§èƒ½æµ‹è¯•")
        
        # ä½¿ç”¨çœŸå®é…ç½®ï¼ˆä½†APIå¯†é’¥ç”¨mockï¼‰
        config_data = {
            'google_api': {
                'api_key': 'real_test_scenario',  # å°†è¢«mock
                'model': 'gemini-2.5-flash',
                'temperature': 0.7,
                'max_tokens': 8192
            },
            'templates': {
                'default_template': 'chinese_transcript',
                'template_path': 'src/gs_video_report/templates/prompts'
            },
            'output': {
                'default_path': str(self.project_root / "test_output"),
                'file_naming': '{video_title}_{timestamp}',
                'include_metadata': True
            }
        }
        self.config = Config(config_data)
        self.monitor = PerformanceMonitor()
    
    @patch('gs_video_report.batch.simple_processor.GeminiService')
    @patch('gs_video_report.batch.simple_processor.TemplateManager')
    def test_real_figma_videos_performance(self, mock_template_manager, mock_gemini_service):
        """
        æµ‹è¯•E1: çœŸå®Figmaæ•™ç¨‹è§†é¢‘æ€§èƒ½æµ‹è¯•
        ç›®æ ‡ï¼šä½¿ç”¨projectä¸­çš„çœŸå®test_videosæµ‹è¯•å®é™…æ€§èƒ½è¡¨ç°
        """
        # æ£€æŸ¥çœŸå®è§†é¢‘æ–‡ä»¶
        video_files = list(self.test_videos_dir.glob("*.mp4"))
        if len(video_files) == 0:
            pytest.skip("æ²¡æœ‰æ‰¾åˆ°çœŸå®çš„æµ‹è¯•è§†é¢‘æ–‡ä»¶")
        
        print(f"ğŸ“ å‘ç° {len(video_files)} ä¸ªçœŸå®Figmaæ•™ç¨‹è§†é¢‘æ–‡ä»¶")
        
        # è®¾ç½®æ¨¡æ‹ŸAPI - æ ¹æ®æ–‡ä»¶å¤§å°æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        mock_service_instance = Mock()
        mock_gemini_service.return_value = mock_service_instance
        
        def realistic_processing_simulation(*args, **kwargs):
            video_path = args[0] if args else kwargs.get('video_path', '')
            try:
                # æ ¹æ®æ–‡ä»¶å¤§å°æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                file_size = Path(video_path).stat().st_size / 1024 / 1024  # MB
                # æ¨¡æ‹Ÿï¼šæ¯MBå¤§çº¦0.1-0.3ç§’å¤„ç†æ—¶é—´
                processing_time = max(0.5, file_size * 0.2 + random.uniform(0.5, 2.0))
                time.sleep(processing_time)
                
                return Mock(output_path=video_path.replace('.mp4', '_lesson.md'))
            except Exception as e:
                # æ–‡ä»¶è®¿é—®é”™è¯¯ç­‰
                time.sleep(0.1)
                raise Exception(f"Simulated processing error: {e}")
        
        import random
        mock_service_instance.process_video_end_to_end.side_effect = realistic_processing_simulation
        
        # å¼€å§‹æ€§èƒ½ç›‘æ§
        self.monitor.start_monitoring()
        
        # æ‰§è¡ŒçœŸå®æ•°æ®æ‰¹é‡å¤„ç†
        processor = SimpleBatchProcessor(self.config)
        start_time = time.time()
        result = processor.process_directory(str(self.test_videos_dir))
        end_time = time.time()
        
        # è·å–æ€§èƒ½æ•°æ®
        perf_data = self.monitor.stop_monitoring()
        processing_time = end_time - start_time
        
        # çœŸå®æ•°æ®æ€§èƒ½éªŒè¯
        total_files = len(video_files)
        success_rate = result["success"] / result["total"]
        throughput = result["total"] / processing_time * 60  # files/min
        
        # æ€§èƒ½æ–­è¨€ï¼ˆåŸºäºçœŸå®åœºæ™¯çš„åˆç†æœŸæœ›ï¼‰
        assert success_rate >= 0.85, f"çœŸå®æ•°æ®æˆåŠŸç‡è¿‡ä½: {success_rate:.2%} < 85%"
        assert processing_time < 3600, f"å¤„ç†æ—¶é—´è¿‡é•¿: {processing_time:.2f}s > 1å°æ—¶"
        assert perf_data['memory']['peak_rss_mb'] < 2048, f"å†…å­˜ä½¿ç”¨è¿‡é«˜: {perf_data['memory']['peak_rss_mb']:.2f}MB"
        
        # çœŸå®åœºæ™¯æ€§èƒ½æŠ¥å‘Š
        performance_report = {
            'test_name': 'E1_real_figma_videos_performance',
            'description': 'Using actual Figma tutorial videos from test_videos/',
            'file_count': total_files,
            'video_files': [f.name for f in video_files],
            'processing_time_seconds': processing_time,
            'throughput_files_per_minute': throughput,
            'success_rate': success_rate,
            'results_breakdown': {
                'success': result["success"],
                'failed': result["failed"],
                'skipped': result["skipped"]
            },
            'performance_metrics': perf_data,
            'file_size_analysis': {
                'total_size_mb': sum(f.stat().st_size for f in video_files) / 1024 / 1024,
                'avg_size_mb': statistics.mean(f.stat().st_size / 1024 / 1024 for f in video_files),
                'largest_file_mb': max(f.stat().st_size / 1024 / 1024 for f in video_files)
            },
            'timestamp': datetime.now().isoformat(),
            'result': 'PASS' if success_rate >= 0.85 else 'FAIL'
        }
        
        # ä¿å­˜è¯¦ç»†çš„çœŸå®æ€§èƒ½æŠ¥å‘Š
        report_file = self.project_root / "tests" / "real_performance_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(performance_report, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… çœŸå®æ•°æ®æ€§èƒ½æµ‹è¯•å®Œæˆ:")
        print(f"   ğŸ“Š æ–‡ä»¶æ•°é‡: {total_files}")
        print(f"   â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.1f}ç§’")
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1%}")
        print(f"   ğŸš€ ååé‡: {throughput:.2f} files/min")
        print(f"   ğŸ’¾ å†…å­˜å³°å€¼: {perf_data['memory']['peak_rss_mb']:.1f}MB")
        print(f"   ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        # æ¸…ç†çŠ¶æ€æ–‡ä»¶
        state_files = list(self.project_root.glob("batch_*_state.json"))
        for state_file in state_files:
            state_file.unlink()


if __name__ == "__main__":
    # å¿«é€Ÿæ€§èƒ½åŸºå‡†æµ‹è¯•
    print("ğŸš€ å¼€å§‹æ‰§è¡Œæ‰¹é‡å¤„ç†æ€§èƒ½åŸºå‡†æµ‹è¯•...")
    
    import subprocess
    import sys
    
    # æ‰§è¡Œå…³é”®æ€§èƒ½æµ‹è¯•
    test_cases = [
        "TestBatchPerformanceBenchmark::test_c1_small_batch_performance_baseline",
        "TestBatchPerformanceBenchmark::test_c2_medium_batch_performance", 
        "TestRealWorldPerformance::test_real_figma_videos_performance"
    ]
    
    for test_case in test_cases:
        print(f"\nğŸ” æ‰§è¡Œæµ‹è¯•: {test_case}")
        result = subprocess.run([
            sys.executable, "-m", "pytest", 
            f"{__file__}::{test_case}",
            "-v", "--tb=short"
        ], cwd=Path(__file__).parent.parent)
        
        if result.returncode == 0:
            print(f"âœ… {test_case} æµ‹è¯•é€šè¿‡")
        else:
            print(f"âŒ {test_case} æµ‹è¯•å¤±è´¥")
